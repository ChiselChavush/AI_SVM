# -*- coding: utf-8 -*-
"""Email_spam_detection_Machine_Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wCdjhCZpJNaNbWQXStAQkyAO4heYDX9n
"""

#Description : This program detects if an email is spam (1) or not (0)

#importing libraries
import numpy as np
import pandas as pd
import nltk
from nltk.corpus import stopwords
import string

#Load the data
from google.colab import files
uploaded = files.upload()

#Read the CSV file
df = pd.read_csv('spam_ham_dataset.csv')

#Print the first 5 rows of data
df.head(5)

#Print the shape (Get the number of rows and colums)
df.shape

#Get the columns names
df.columns

#Check for duplicates and remove them
df.drop_duplicates(inplace = True)

#Show the new shape(number of row and columns)
df.shape

#Show the number of missing (NAN, NaN, na)data for each column
df.isnull().sum()

#Download the stopwords package
nltk.download('stopwords')

def process_text(text):
  #1 Remove the punctuation
  #2 Remove stopwords
  #3 return a list of a clean text words

  #1
  nopunc = [char for char in text if char not in string.punctuation]
  nopunc = ''.join(nopunc)

  #2
  clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]
  
  #3
  return clean_words

# Show the tokenization (a list of tokens also called lemmas)
df['text'].head().apply(process_text)

#Example 

message4 = 'hello world hello hello world play'
message5 = 'test test test test one hello'
print(message4)
print()

#Convert the text to a matrix of token counts
#sklearn is a machine learning library
from sklearn.feature_extraction.text import CountVectorizer
bow4 = CountVectorizer(analyzer=process_text).fit_transform([[message4], [message5]])
print(bow4)
print()

print(bow4.shape)

#Convert a collection of text to a matrix of tokens
from sklearn.feature_extraction.text import CountVectorizer
messages_bow = CountVectorizer(analyzer=process_text).fit_transform(df['text'])

#Split the data into %80 training and %20 testing
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(messages_bow, df['label_num'], test_size = 0.20, random_state= 0)

#Get the shape of messages_bow (5171 row of data and 50381 colums in our data set)
messages_bow.shape

#Create a train the Naive Bayes Classifier (The model that we are using for our prediction(multinomial naive bayes classifier))
from sklearn.naive_bayes import MultinomialNB
classifier = MultinomialNB().fit(X_train, y_train)

#Print the predictions
print(classifier.predict(X_train))

#Print the actual values
print(y_train.values)

#Evaluate the model on the training data set
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
pred = classifier.predict(X_train)
print(classification_report(y_train, pred))
print()
print('Confusion Matrix: \n', confusion_matrix(y_train, pred))
print()
print('Accuracy: ', accuracy_score(y_train, pred))

#Print the predictions
print(classifier.predict(X_test))

#Print the actual values
print(y_test.values)

#Evaluate the model on the training data set
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
pred = classifier.predict(X_test)
print(classification_report(y_test, pred))
print()
print('Confusion Matrix: \n', confusion_matrix(y_test, pred))
print()
print('Accuracy: ', accuracy_score(y_test, pred))